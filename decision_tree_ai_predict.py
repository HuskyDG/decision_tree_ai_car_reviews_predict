# -*- coding: utf-8 -*-
"""btlop2 (4).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1pDzPxj9QLTQYZDV_OFNupVQIEJrswXKX

# **Dữ liệu**
"""

# Commented out IPython magic to ensure Python compatibility.
#import thư
import pandas as pd
import numpy as np
from matplotlib import pyplot as plt
# %matplotlib inline
import seaborn as sns
!pip install treelib
from google.colab import files

#Đọc file
df = pd.read_csv("car.data");

print(df)

#chuyển đổi dữ liệu cột phân loại chỉ còn 2 thuộc tính good và bad
for index in range(len(df)):
  end_clmns = df[df.columns[len(df.columns)-1]][index]
  if end_clmns == "unacc":
      df[df.columns[len(df.columns)-1]][index] = "bad"
  else:
      df[df.columns[len(df.columns)-1]][index] = "good"

print(df)

#Xem số dòng số cột
df.shape

#Xem thuộc tính
df.columns

"""# **Trực quan hóa dữ liệu**"""

#Biểu đồ thể hiện mối tương quan giữa cột chi phí và đánh giá
fig, axs = plt.subplots(figsize=(20,3))
crosstab = pd.crosstab(df['cost'], df['Reviews'])
sns.heatmap(crosstab, annot=True, cmap='coolwarm')
plt.show()

#Biểu đồ thể hiện mối tương quan giữa cột bảo trì và đánh giá
fig, axs = plt.subplots(figsize=(20,3))
crosstab = pd.crosstab(df['maintenance'], df['Reviews'])
sns.heatmap(crosstab, annot=True, cmap='coolwarm')
plt.show()

#Biểu đồ thể hiện mối tương quan giữa cột số cửa xe và đánh giá
fig, axs = plt.subplots(figsize=(20,3))
crosstab = pd.crosstab(df['numberOfDoors'], df['Reviews'])
sns.heatmap(crosstab, annot=True, cmap='coolwarm')
plt.show()

#Biểu đồ thể hiện mối tương quan giữa cột số người và đánh giá
fig, axs = plt.subplots(figsize=(20,3))
crosstab = pd.crosstab(df['numberOfPeople'], df['Reviews'])
sns.heatmap(crosstab, annot=True, cmap='coolwarm')
plt.show()

#Biểu đồ thể hiện mối tương quan giữa cột cóp xe và đánh giá
fig, axs = plt.subplots(figsize=(20,3))
crosstab = pd.crosstab(df['Trunk'], df['Reviews'])
sns.heatmap(crosstab, annot=True, cmap='coolwarm')
plt.show()

#Biểu đồ thể hiện mối tương quan giữa cột độ an toàn và đánh giá
fig, axs = plt.subplots(figsize=(20,3))
crosstab = pd.crosstab(df['Safety'], df['Reviews'])
sns.heatmap(crosstab, annot=True, cmap='coolwarm')
plt.show()

"""# **Làm sạch dữ liệu**"""

#Xem số giá trị null ở mỗi cột
df.isnull().sum()

#Gán giá trị NaN của cột Chi phí dựa theo cột bảo trì
for i in range(len(df)):
    if pd.isnull(df.loc[i, 'cost']):
        df.loc[i, 'cost'] = df.loc[i, 'maintenance']
df

#Gán giá trị NaN của cột bảo trì dựa theo cột chi phí

for i in range(len(df)):
    if pd.isnull(df.loc[i, 'maintenance']):
        df.loc[i, 'maintenance'] = df.loc[i, 'cost']
df

#Gán giá trị NaN của cột so-cua-xe dựa theo cột so-nguoi
mode_df = df.groupby('numberOfPeople')['numberOfDoors'].agg(pd.Series.mode).reset_index()
print(mode_df)
for i in range(len(df)):
    if pd.isnull(df.loc[i, 'numberOfDoors']):
        temp_df = mode_df[mode_df['numberOfPeople'] == df.loc[i, 'numberOfPeople']]['numberOfDoors']
        if not temp_df.empty:
            df.loc[i, 'numberOfDoors'] = temp_df.values[0]
df

#Gán giá trị NaN của cột so-nguoi dựa theo cột  so-cua-xe
mode_df = df.groupby('numberOfDoors')['numberOfPeople'].agg(pd.Series.mode).reset_index()
print(mode_df)
for i in range(len(df)):
    if pd.isnull(df.loc[i, 'numberOfPeople']):
        temp_df = mode_df[mode_df['numberOfDoors'] == df.loc[i, 'numberOfDoors']]['numberOfPeople']
        if not temp_df.empty:
            df.loc[i, 'numberOfPeople'] = temp_df.values[0]
df

#Gán giá trị NaN của cột "cóp xe" dựa theo cột "chi phí"
mode_df = df.groupby('cost')['Trunk'].agg(pd.Series.mode).reset_index()
print(mode_df)
for i in range(len(df)):
    if pd.isnull(df.loc[i, 'Trunk']):
        df.loc[i, 'Trunk'] = mode_df[mode_df['cost'] == df.loc[i, 'cost']]['Trunk'].values[0]
df

#Gán giá trị NaN của cột "độ an toàn" dựa theo cột "chi phí"
mode_df = df.groupby('cost')['Safety'].agg(pd.Series.mode).reset_index()
print(mode_df)
# Điền giá trị bị thiếu trong cột "độ an toàn" dựa trên mode tương ứng của cột "chi phí"
for i in range(len(df)):
    if pd.isnull(df.loc[i, 'Safety']):
        df.loc[i, 'Safety'] = mode_df[mode_df['cost'] == df.loc[i, 'cost']]['Safety'].values[0]
df

#xóa dòng dữ liệu có giá trị null mà không đủ cơ sở để bổ sung
df = df.dropna()

#Xem số giá trị null ở mỗi cột
df.isnull().sum()

# Kiểm tra dòng dữ liệu trùng lặp
df = df.astype(str)
trunglap = df.duplicated()

# In ra số lượng dòng dữ liệu trùng lặp
print("Số lượng dòng dữ liệu trùng lặp:", trunglap.sum())

# Nếu bạn muốn xem các dòng dữ liệu trùng lặp
print("Các dòng dữ liệu trùng lặp:")
print(df[trunglap])

#xóa dòng dữ liệu bị trùng
df = df.drop_duplicates()

# Kiểm tra dòng dữ liệu trùng lặp
df = df.astype(str)
trunglap = df.duplicated()

# In ra số lượng dòng dữ liệu trùng lặp
print("Số lượng dòng dữ liệu trùng lặp:", trunglap.sum())

# Nếu bạn muốn xem các dòng dữ liệu trùng lặp
print("Các dòng dữ liệu trùng lặp:")
print(df[trunglap])

#Chuẩn hóa dữ liệu về dạng số

df.reset_index(drop=True, inplace=True)
def standardized_to_number(df):
    MyDict = {}
    ReversedDict = {}

    for cols in df.columns:
        no = 0
        for value in set(df[cols]):
            MyDict.update({(cols, value): no})
            ReversedDict.update({(cols, no): value})
            no = no + 1
    for cols in df.columns:
        for index in range(len(df[cols])):
            df[cols][index] = MyDict[(cols, df[cols][index])]
    return df, MyDict, ReversedDict

def replace_with_dict(df, ReplaceDict):
    for cols in df.columns:
        for index in range(len(df[cols])):
            df[cols][index] = ReplaceDict[(cols, df[cols][index])]
    return df


df, MyDict, ReversedDict = standardized_to_number(df)
print(MyDict)
print(df)

df.to_csv("./car_test2.txt")

"""## **Mô hình decision tree**"""

from pickle import FALSE
import math

# Khai báo lớp Node
class Node:
    #  Khởi tạo attribute, threshold, label, and children
    def __init__(self, attribute=None, threshold=None, label=None, children=None):
        self.attribute = attribute
        self.threshold = threshold
        self.label = label
        self.children = children


# Khởi tạo hàm để xây cây
def build_tree(data, labels, max_depth, min_size):
    #print(data)
    #print(labels)

    labels_set = set(labels);
    if len(labels_set) == 1 or max_depth == 0:
        label = max(set(labels), key=labels.count)
        return Node(attribute=None, label=label)

    occurences_count = {}
    H_purity = {}

    # lưu số lần xuất hiện các giá trị để lát ta tính H đó
    for rows in data.columns:
        for cols in set(data[rows]):
            occurences_count.update({(rows, cols) : 0})
            for dec in set(labels):
                occurences_count.update({(rows, cols, dec) : 0})
        for i in range(len(data[rows])):
            cols = data[rows][i]
            dec = labels[i]
            # số lần xuất hiện: { rows,cols : new_occurences }
            new_occurences = occurences_count[(rows, cols)] + 1
            occurences_count.update({(rows, cols): new_occurences})
            # số lần xuất hiện: { rows,cols,decision : new_occurences }
            new_occurences = occurences_count[(rows, cols, dec)] + 1
            occurences_count.update({(rows, cols, dec): new_occurences})

    # Biến này dùng để lưu tên cột với H nhỏ nhất
    H_purity_min = data.columns[0]

    for i in data.columns: #với mỗi columns
        for j in set(data[i]): #với mỗi giá trị đầu vào
            H = float(0)
            for k in labels_set:
                # sử dụng công thức tính H
                r = float(occurences_count[(i,j,k)]) / occurences_count[(i,j)]
                if r != 0:
                    H = H - (r*(math.log(r)/math.log(2)))
            H_purity.update({(i,j): H})
        H = float(0)
        for j in set(data[i]): #với mỗi giá trị đầu vào
            r = float(occurences_count[(i,j)])/len(labels) * H_purity[(i,j)]
            H = H + r
        H_purity.update({i: H})
        if H_purity[H_purity_min] > H_purity[i]:
            H_purity_min = i

    # Phân tách thành dữ liệu con để tiếp tục xây cây
    children = []
    for t in set(data[H_purity_min]):
        subsets = pd.DataFrame()
        subset_labels = []
        for index, rows in data.iterrows():
            if rows[H_purity_min] == t:
                dict_tmp = {}
                for i in data.columns:
                    if i != H_purity_min:
                        dict_tmp.update({i : rows[i]})
                        subset_labels.append(labels[index])
                subsets = subsets._append(dict_tmp,ignore_index=True)
        # gọi hàm đệ quy để tiếp tục xây cây
        child = build_tree(subsets, subset_labels, max_depth - 1, min_size)
        children.append(child)
    return Node(attribute=H_purity_min, threshold=set(data[H_purity_min]), children=children)


# Khai báo hàm để đưa ra dự đoám
def predict(node, data, instance):
    #nếu là node lá
    if node.label is not None:
        return node.label

    if data[node.attribute][instance] in node.threshold:
        index = -1
        for key in node.threshold:
          index = index + 1
          if key == data[node.attribute][instance]:
              return predict(node.children[index], data, instance)
              break

class DecisionTreeClassifier:
    def __init__(self, max_depth=10, min_size=2):
        self.max_depth = max_depth
        self.min_size = min_size
        self.root = None


    def fit(self, data, labels):
        self.root = build_tree(data, labels, self.max_depth, self.min_size)

    def predict(self, data):
        predictions = []
        for instance in range(len(data)):
            prediction = predict(self.root, data, instance)
            predictions.append(prediction)
        return predictions


Y= df[df.columns[len(df.columns)-1]]
X= df.drop(columns=df.columns[len(df.columns)-1])

#Tạo mô hình dự đoán
model = DecisionTreeClassifier()

#Huấn luyện để tạo cây quyết định
model.fit(X,Y)

def get_blank(count):
    blank=""
    while count > 0:
        blank = blank +  "    "
        count = count -1
    return blank

import treelib
import random

tree = treelib.Tree()
def print_tree(node, tree, new_tree = True, lv = 0, id = 0):
    if (node.attribute == None):
        print(get_blank(lv), "Decide: ", node.label)
        return
    if new_tree == True:
        tree.create_node(node.attribute, str(id));
    print(get_blank(lv), "Node:", node.attribute)
    if node.threshold == None:
        return
    for i in range(len(node.threshold)):
        child_id = random.randint(0, 99999999)
        child_attr = node.children[i].attribute
        addition = ""
        if (child_attr == None):
            child_attr=node.children[i].label
            addition = "-[leaf]"

        tree.create_node(node.attribute + "=" + str(tuple(node.threshold)[i]) \
                         , str(child_id) + "-[attr]", parent = str(id))
        tree.create_node(str(child_attr) \
                         , str(child_id) + addition, parent=(str(child_id) + "-[attr]"))
        print(get_blank(lv+1), node.attribute, "=", tuple(node.threshold)[i])
        print_tree(node.children[i], tree, False, lv+1, child_id)

print_tree(model.root, tree)

import graphviz

tree.to_graphviz(filename="tree_graph.txt")
with open('tree_graph.txt') as f:
    dot_graph = f.read()

dot_graph_new = ""

for line in dot_graph.splitlines():
    if line.find("-[attr]") != -1:
        line = line.replace("shape=circle", "shape=plaintext")
    if line.find("-[leaf]") == -1:
        line = line.replace("shape=circle", "shape=rectangle")
    dot_graph_new = dot_graph_new + line + "\n"

print(dot_graph_new)

g = graphviz.Source(dot_graph_new)
g.format="png"
g

df_test = pd.read_csv("./car_test.txt")

df_test.drop(df['Reviews'])

model.predict(df_test)